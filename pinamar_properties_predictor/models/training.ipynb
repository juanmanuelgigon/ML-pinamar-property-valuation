{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30a8928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ff703aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precio                       0\n",
       "m2                           0\n",
       "ambientes                    0\n",
       "dormitorios                  0\n",
       "baños                        0\n",
       "cocheras                     0\n",
       "es_a_refaccionar             0\n",
       "tiene_quincho                0\n",
       "m2_construidos_final         0\n",
       "pileta_m2_real               0\n",
       "tiene_jardin                 0\n",
       "estado_desc                  0\n",
       "tiene_vista_mar              0\n",
       "es_cercano_mar               0\n",
       "gas_natural                  0\n",
       "losa_radiante                0\n",
       "porcentaje_cubierto          0\n",
       "es_ph_loft                   0\n",
       "estilo_antiguedad            0\n",
       "tipo_detectado               0\n",
       "barrio_detectado             0\n",
       "m2_no_construidos            0\n",
       "es_lujosa_hardware           0\n",
       "ratio_bano_dormitorio        0\n",
       "factor_parque                0\n",
       "tiene_seguridad              0\n",
       "es_moderna_estrenar          0\n",
       "dependencia_servicio         0\n",
       "doble_vidrio_dvh             0\n",
       "cochera_cerrada              0\n",
       "nivel_pileta                 0\n",
       "es_renovada                  0\n",
       "en_complejo                  0\n",
       "ambientes_extra              0\n",
       "ratio_dormitorio_ambiente    0\n",
       "cantidad_plantas             0\n",
       "precio_m2                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ready-props-pinamar.csv')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b37d5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_numericas = [\n",
    "    'm2',\n",
    "    #'m2_no_construidos', \n",
    "    'm2_construidos_final',\n",
    "    'ambientes', \n",
    "    'dormitorios', \n",
    "    'baños', \n",
    "    'cocheras', \n",
    "    'nivel_pileta', 'cantidad_plantas',\n",
    "    #'pileta_m2_real', \n",
    "    'ratio_bano_dormitorio',  'ambientes_extra', 'ratio_dormitorio_ambiente',\n",
    "]   \n",
    "    #'factor_parque' \n",
    "\n",
    "# B. Categóricas (Texto que define valor)\n",
    "# 'barrio_detectado' es CRÍTICA. 'estado_desc' ayuda mucho.\n",
    "cols_categoricas = [\n",
    "    'barrio_detectado', 'estilo_antiguedad',\n",
    "    #'tipo_detectado',\n",
    "    'estado_desc'\n",
    "]\n",
    "\n",
    "# C. Binarias (0 o 1 - Características Clave)\n",
    "# Aquí agregamos las variables \"Estrella\" de Pinamar que creamos recién.\n",
    "cols_binarias = [\n",
    "    'es_a_refaccionar', \n",
    "    'es_lujosa_hardware',  'dependencia_servicio', 'doble_vidrio_dvh', \n",
    "    #'tiene_pileta', \n",
    "    #'tiene_quincho', \n",
    "    'losa_radiante',\n",
    "    'es_cercano_mar',\n",
    "    #'tiene_vista_mar',  \n",
    "    'gas_natural',     'es_ph_loft',\n",
    "    'tiene_seguridad', 'es_renovada',  'en_complejo', 'es_moderna_estrenar'\n",
    "]\n",
    "\n",
    "cols_numericas = [c for c in cols_numericas if c in df.columns]\n",
    "cols_categoricas = [c for c in cols_categoricas if c in df.columns]\n",
    "cols_binarias = [c for c in cols_binarias if c in df.columns]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler()) \n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Desconocido')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, cols_numericas),\n",
    "        ('cat', categorical_transformer, cols_categoricas),\n",
    "        ('bin', binary_transformer, cols_binarias) \n",
    "    ],\n",
    "    verbose_feature_names_out=False \n",
    ").set_output(transform=\"pandas\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4d77059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Shape X_train_proc: (876, 42)\n",
      "   Shape X_val_proc:   (219, 42)\n"
     ]
    }
   ],
   "source": [
    "X = df[cols_numericas + cols_categoricas + cols_binarias] \n",
    "y = df['precio']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "print(f\"   Shape X_train_proc: {X_train_proc.shape}\")\n",
    "print(f\"   Shape X_val_proc:   {X_val_proc.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d232d2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocesador y datos de validación guardados\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(preprocessor, 'trained_models/preprocesador_pinamar.pkl')\n",
    "joblib.dump((X_val, y_val), '../data/datos_validacion.pkl')\n",
    "print(\"Preprocesador y datos de validación guardados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39c44401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score (Train):       0.5997\n",
      "Error Promedio (Train): 22.44%\n",
      "Modelo entrenado y guardado\n"
     ]
    }
   ],
   "source": [
    "model_lr = LinearRegression(n_jobs=-1)\n",
    "\n",
    "model_lr.fit(X_train_proc, y_train)\n",
    "\n",
    "y_pred_train = model_lr.predict(X_train_proc)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_pred_train) * 100\n",
    "\n",
    "print(f\"R2 Score (Train):       {r2_train:.4f}\")\n",
    "print(f\"Error Promedio (Train): {mape_train:.2f}%\")\n",
    "\n",
    "joblib.dump(model_lr, 'trained_models/modelo_lineal_pinamar.pkl')\n",
    "\n",
    "print(\"Modelo entrenado y guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4dd3783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score (Train):       0.5681\n",
      "Error Promedio (Train): 21.35%\n",
      "Modelo logarítmico entrenado y guardado \n"
     ]
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "model_lr = LinearRegression(n_jobs=-1)\n",
    "model_lr.fit(X_train_proc, y_train_log)\n",
    "\n",
    "y_pred_train_log = model_lr.predict(X_train_proc)\n",
    "\n",
    "y_pred_train = np.expm1(y_pred_train_log)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_pred_train) * 100\n",
    "\n",
    "print(f\"R2 Score (Train):       {r2_train:.4f}\")\n",
    "print(f\"Error Promedio (Train): {mape_train:.2f}%\")\n",
    "\n",
    "joblib.dump(model_lr, 'trained_models/modelo_lineal_log_pinamar.pkl')\n",
    "print(\"Modelo logarítmico entrenado y guardado \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "641a4993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejor Config. Normal: {'n_estimators': 300, 'min_samples_leaf': 2, 'max_features': 1.0, 'max_depth': None, 'bootstrap': True}\n",
      "MAPE Train: 10.90%\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejor Config. Logarítmica: {'n_estimators': 500, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': None, 'bootstrap': True}\n",
      "MAPE Train: 7.75%\n",
      "\n",
      "Ambos modelos optimizados, entrenados y guardados\n"
     ]
    }
   ],
   "source": [
    "param_dist_rf = {\n",
    "    'n_estimators': [200, 300, 500],       \n",
    "    'max_depth': [10, 15, 20, 25, None],       \n",
    "    'min_samples_leaf': [1, 2, 4],              \n",
    "    'max_features': ['sqrt', 'log2', 1.0],     \n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "rf_base = RandomForestRegressor(random_state=69)\n",
    "\n",
    "search_rf_normal = RandomizedSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=20,                                    \n",
    "    scoring='neg_mean_absolute_percentage_error',  \n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=69\n",
    ")\n",
    "search_rf_normal.fit(X_train_proc, y_train)\n",
    "\n",
    "best_rf_normal = search_rf_normal.best_estimator_\n",
    "\n",
    "y_pred_train_rf = best_rf_normal.predict(X_train_proc)\n",
    "mape_train_rf = mean_absolute_percentage_error(y_train, y_pred_train_rf) * 100\n",
    "\n",
    "print(f\"Mejor Config. Normal: {search_rf_normal.best_params_}\")\n",
    "print(f\"MAPE Train: {mape_train_rf:.2f}%\")\n",
    "\n",
    "joblib.dump(best_rf_normal, 'trained_models/modelo_rf_opt_pinamar.pkl')\n",
    "\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "search_rf_log = RandomizedSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=20,\n",
    "    scoring='neg_mean_squared_error', \n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "search_rf_log.fit(X_train_proc, y_train_log)\n",
    "\n",
    "best_rf_log = search_rf_log.best_estimator_\n",
    "\n",
    "y_pred_train_log = best_rf_log.predict(X_train_proc)\n",
    "y_pred_train_rf_log = np.expm1(y_pred_train_log)\n",
    "mape_train_rf_log = mean_absolute_percentage_error(y_train, y_pred_train_rf_log) * 100\n",
    "\n",
    "print(f\"Mejor Config. Logarítmica: {search_rf_log.best_params_}\")\n",
    "print(f\"MAPE Train: {mape_train_rf_log:.2f}%\")\n",
    "\n",
    "joblib.dump(best_rf_log, 'trained_models/modelo_rf_log_opt_pinamar.pkl')\n",
    "\n",
    "print(\"\\nAmbos modelos optimizados, entrenados y guardados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed4d74b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_dir/house_pricing_tuning/tuner0.json\n",
      "Mejor configuración encontrada:\n",
      " - Neuronas Capa 1: 64\n",
      " - Dropout Capa 1: 0.4\n",
      " - Neuronas Capa 2: 128\n",
      " - Dropout Capa 2: 0.4\n",
      " - Learning Rate: 0.01\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanmanuel/Desktop/proyectoMl/.venv/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.3373 - val_loss: 1.2429\n",
      "Epoch 2/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4150 - val_loss: 0.9758\n",
      "Epoch 3/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8665 - val_loss: 0.8609\n",
      "Epoch 4/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9038 - val_loss: 1.9089\n",
      "Epoch 5/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5983 - val_loss: 0.9746\n",
      "Epoch 6/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3763 - val_loss: 1.2476\n",
      "Epoch 7/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3280 - val_loss: 0.6420\n",
      "Epoch 8/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1076 - val_loss: 0.4075\n",
      "Epoch 9/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9970 - val_loss: 0.9798\n",
      "Epoch 10/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8827 - val_loss: 0.4083\n",
      "Epoch 11/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8099 - val_loss: 0.3400\n",
      "Epoch 12/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7475 - val_loss: 0.6291\n",
      "Epoch 13/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6894 - val_loss: 0.3039\n",
      "Epoch 14/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7098 - val_loss: 0.4287\n",
      "Epoch 15/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6587 - val_loss: 0.2799\n",
      "Epoch 16/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6226 - val_loss: 0.2537\n",
      "Epoch 17/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5802 - val_loss: 0.4753\n",
      "Epoch 18/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5385 - val_loss: 0.2932\n",
      "Epoch 19/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5559 - val_loss: 0.4378\n",
      "Epoch 20/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5186 - val_loss: 0.3557\n",
      "Epoch 21/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5319 - val_loss: 0.5508\n",
      "Epoch 22/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5186 - val_loss: 0.4370\n",
      "Epoch 23/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4504 - val_loss: 0.4260\n",
      "Epoch 24/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4034 - val_loss: 0.2719\n",
      "Epoch 25/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3460 - val_loss: 0.2254\n",
      "Epoch 26/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3432 - val_loss: 0.4048\n",
      "Epoch 27/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3130 - val_loss: 0.2202\n",
      "Epoch 28/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3042 - val_loss: 0.3615\n",
      "Epoch 29/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3159 - val_loss: 0.2728\n",
      "Epoch 30/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2612 - val_loss: 0.2296\n",
      "Epoch 31/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3252 - val_loss: 0.3237\n",
      "Epoch 32/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2764 - val_loss: 0.2636\n",
      "Epoch 33/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2503 - val_loss: 0.2031\n",
      "Epoch 34/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2481 - val_loss: 0.2038\n",
      "Epoch 35/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2530 - val_loss: 0.2243\n",
      "Epoch 36/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2594 - val_loss: 0.1971\n",
      "Epoch 37/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2379 - val_loss: 0.1988\n",
      "Epoch 38/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2403 - val_loss: 0.2117\n",
      "Epoch 39/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2450 - val_loss: 0.2337\n",
      "Epoch 40/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2306 - val_loss: 0.2024\n",
      "Epoch 41/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2447 - val_loss: 0.2109\n",
      "Epoch 42/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2283 - val_loss: 0.1989\n",
      "Epoch 43/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2232 - val_loss: 0.2050\n",
      "Epoch 44/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2375 - val_loss: 0.2243\n",
      "Epoch 45/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2286 - val_loss: 0.2017\n",
      "Epoch 46/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2453 - val_loss: 0.1918\n",
      "Epoch 47/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2206 - val_loss: 0.2216\n",
      "Epoch 48/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2317 - val_loss: 0.2159\n",
      "Epoch 49/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2307 - val_loss: 0.2015\n",
      "Epoch 50/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2260 - val_loss: 0.2039\n",
      "Epoch 51/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2314 - val_loss: 0.2156\n",
      "Epoch 52/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2312 - val_loss: 0.2007\n",
      "Epoch 53/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2392 - val_loss: 0.2163\n",
      "Epoch 54/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2306 - val_loss: 0.2021\n",
      "Epoch 55/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2227 - val_loss: 0.2092\n",
      "Epoch 56/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2216 - val_loss: 0.1921\n",
      "Epoch 57/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2209 - val_loss: 0.2015\n",
      "Epoch 58/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2276 - val_loss: 0.2093\n",
      "Epoch 59/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2151 - val_loss: 0.2120\n",
      "Epoch 60/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2239 - val_loss: 0.2122\n",
      "Epoch 61/500\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2515 - val_loss: 0.2408\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "RESULTADOS RED NEURONAL (En USD)\n",
      "TRAIN\n",
      "R2 Score:        0.6211\n",
      "Error Promedio:  18.12%\n",
      "Error Mediano:   14.39%\n",
      "VALIDATION\n",
      "R2 Score:        0.5463\n",
      "Error Promedio:  18.92%\n",
      "Error Mediano:   14.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log(y_val)\n",
    "\n",
    "input_dim = X_train_proc.shape[1]\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Capa de Entrada + Oculta 1 (Buscando entre 64 y 256 neuronas)\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_1', min_value=64, max_value=256, step=64),\n",
    "        activation='relu',\n",
    "        input_shape=(input_dim,)\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.4, step=0.1)))\n",
    "    \n",
    "    # Capa Oculta 2 (Buscando entre 32 y 128 neuronas)\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.4, step=0.1)))\n",
    "    \n",
    "    # Capa Oculta 3 fija para estabilizar antes de la salida\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    # Capa de Salida: 1 neurona lineal para el Log(Precio)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # Optimizador: Buscando el mejor Learning Rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='mean_absolute_error' # Evaluamos el error sobre el logaritmo\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,    \n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='house_pricing_tuning'\n",
    ")\n",
    "\n",
    "early_stop_tuner = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "tuner.search(\n",
    "    X_train_proc, y_train_log,\n",
    "    validation_data=(X_val_proc, y_val_log),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop_tuner],\n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_nn = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "print(f\"Mejor configuración encontrada:\")\n",
    "print(f\" - Neuronas Capa 1: {best_hps.get('units_1')}\")\n",
    "print(f\" - Dropout Capa 1: {best_hps.get('dropout_1')}\")\n",
    "print(f\" - Neuronas Capa 2: {best_hps.get('units_2')}\")\n",
    "print(f\" - Dropout Capa 2: {best_hps.get('dropout_2')}\")\n",
    "print(f\" - Learning Rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "# ENTRENAR EL MODELO FINAL\n",
    "early_stop_final = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model_nn.fit(\n",
    "    X_train_proc, y_train_log,\n",
    "    validation_data=(X_val_proc, y_val_log),\n",
    "    epochs=500,          \n",
    "    batch_size=32,       \n",
    "    callbacks=[early_stop_final],\n",
    "    verbose=1            \n",
    ")\n",
    "\n",
    "y_pred_log_train = model_nn.predict(X_train_proc).flatten()\n",
    "y_pred_train = np.expm1(y_pred_log_train)\n",
    "\n",
    "y_pred_log_val = model_nn.predict(X_val_proc).flatten()\n",
    "y_pred_val = np.exp(y_pred_log_val)\n",
    "\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    mediana = np.median(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    print(f\"{dataset_name.upper()}\")\n",
    "    print(f\"R2 Score:        {r2:.4f}\")\n",
    "    print(f\"Error Promedio:  {mape:.2f}%\")\n",
    "    print(f\"Error Mediano:   {mediana:.2f}%\")\n",
    "\n",
    "print(\"RESULTADOS RED NEURONAL (En USD)\")\n",
    "print_metrics(y_train, y_pred_train, \"Train\")\n",
    "print_metrics(y_val, y_pred_val, \"Validation\")\n",
    "\n",
    "# Gráfico de pérdida (Loss) en escala logarítmica\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Error Entrenamiento (Log)')\n",
    "plt.plot(history.history['val_loss'], label='Error Validación (Log)')\n",
    "plt.title('Curva de Aprendizaje del Modelo Final')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Error MAE (Logaritmo del Precio)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "resultados_nn = pd.DataFrame({\n",
    "    'Precio Real USD': y_val.values,\n",
    "    'Predicción NN USD': y_pred_val.round(0),\n",
    "    'Diferencia USD': (y_val.values - y_pred_val).round(0),\n",
    "    'Error %': ((y_pred_val - y_val.values) / y_val.values * 100).round(1)\n",
    "})\n",
    "model_nn.save('trained_models/modelo_nn_pinamar.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67186f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_dir/house_pricing_tuning/tuner0.json\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanmanuel/Desktop/proyectoMl/.venv/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.7742 - val_loss: 2.6313\n",
      "Epoch 2/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5948 - val_loss: 2.3178\n",
      "Epoch 3/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1465 - val_loss: 1.0863\n",
      "Epoch 4/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1135 - val_loss: 0.9659\n",
      "Epoch 5/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8378 - val_loss: 2.5581\n",
      "Epoch 6/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7647 - val_loss: 0.8153\n",
      "Epoch 7/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4553 - val_loss: 0.7256\n",
      "Epoch 8/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4162 - val_loss: 0.8550\n",
      "Epoch 9/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2177 - val_loss: 1.0320\n",
      "Epoch 10/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3344 - val_loss: 0.8036\n",
      "Epoch 11/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1222 - val_loss: 0.4593\n",
      "Epoch 12/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9846 - val_loss: 0.3680\n",
      "Epoch 13/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9181 - val_loss: 0.7079\n",
      "Epoch 14/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8948 - val_loss: 0.3843\n",
      "Epoch 15/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7937 - val_loss: 0.5625\n",
      "Epoch 16/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7550 - val_loss: 0.3528\n",
      "Epoch 17/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7567 - val_loss: 1.2404\n",
      "Epoch 18/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7344 - val_loss: 0.3986\n",
      "Epoch 19/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6830 - val_loss: 0.4049\n",
      "Epoch 20/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7031 - val_loss: 0.2689\n",
      "Epoch 21/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6252 - val_loss: 0.2942\n",
      "Epoch 22/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5903 - val_loss: 0.3438\n",
      "Epoch 23/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5772 - val_loss: 0.3482\n",
      "Epoch 24/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5983 - val_loss: 0.3187\n",
      "Epoch 25/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5327 - val_loss: 0.3184\n",
      "Epoch 26/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4648 - val_loss: 0.3276\n",
      "Epoch 27/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4837 - val_loss: 0.2945\n",
      "Epoch 28/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4452 - val_loss: 0.3622\n",
      "Epoch 29/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4392 - val_loss: 0.2986\n",
      "Epoch 30/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4194 - val_loss: 0.2955\n",
      "Epoch 31/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4168 - val_loss: 0.2577\n",
      "Epoch 32/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3622 - val_loss: 0.3521\n",
      "Epoch 33/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3417 - val_loss: 0.2818\n",
      "Epoch 34/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3267 - val_loss: 0.5473\n",
      "Epoch 35/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3737 - val_loss: 0.2458\n",
      "Epoch 36/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3312 - val_loss: 0.5517\n",
      "Epoch 37/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3388 - val_loss: 0.3392\n",
      "Epoch 38/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2790 - val_loss: 0.3384\n",
      "Epoch 39/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2946 - val_loss: 0.3956\n",
      "Epoch 40/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2753 - val_loss: 0.2541\n",
      "Epoch 41/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2627 - val_loss: 0.2672\n",
      "Epoch 42/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2423 - val_loss: 0.2723\n",
      "Epoch 43/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2269 - val_loss: 0.2378\n",
      "Epoch 44/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2579 - val_loss: 0.3960\n",
      "Epoch 45/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2673 - val_loss: 0.2634\n",
      "Epoch 46/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2715 - val_loss: 0.2816\n",
      "Epoch 47/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2536 - val_loss: 0.2542\n",
      "Epoch 48/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2327 - val_loss: 0.2564\n",
      "Epoch 49/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2401 - val_loss: 0.2609\n",
      "Epoch 50/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2323 - val_loss: 0.2448\n",
      "Epoch 51/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2244 - val_loss: 0.2880\n",
      "Epoch 52/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2302 - val_loss: 0.2651\n",
      "Epoch 53/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2240 - val_loss: 0.2419\n",
      "Epoch 54/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2275 - val_loss: 0.2494\n",
      "Epoch 55/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2147 - val_loss: 0.2588\n",
      "Epoch 56/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2195 - val_loss: 0.2514\n",
      "Epoch 57/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2276 - val_loss: 0.2883\n",
      "Epoch 58/500\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2186 - val_loss: 0.2595\n",
      "\n",
      "Modelo guardado\n"
     ]
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "input_dim = X_train_proc.shape[1]\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Capa de Entrada + Oculta 1\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_1', min_value=64, max_value=256, step=64),\n",
    "        activation='relu',\n",
    "        input_shape=(input_dim,)\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.4, step=0.1)))\n",
    "    \n",
    "    # Capa Oculta 2\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_2', min_value=32, max_value=128, step=32),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.4, step=0.1)))\n",
    "    \n",
    "    # Capa Oculta 3 fija\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    # Capa de Salida (Lineal para el Logaritmo del Precio)\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # Optimizador\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='mean_absolute_error'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_dir',\n",
    "    project_name='house_pricing_tuning'\n",
    ")\n",
    "\n",
    "early_stop_tuner = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "tuner.search(\n",
    "    X_train_proc, y_train_log,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop_tuner],\n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_nn = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "early_stop_final = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model_nn.fit(\n",
    "    X_train_proc, y_train_log,\n",
    "    validation_split=0.2,         \n",
    "    epochs=500,          \n",
    "    batch_size=32,       \n",
    "    callbacks=[early_stop_final],\n",
    "    verbose=1            \n",
    ")\n",
    "model_nn.save('trained_models/modelo_casas_pinamar.keras')\n",
    "print(\"\\nModelo guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51fe7f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_robust_dir/house_pricing_robust_tuning/tuner0.json\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanmanuel/Desktop/proyectoMl/.venv/lib/python3.13/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/juanmanuel/Desktop/proyectoMl/.venv/lib/python3.13/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.9843 - val_loss: 7.6491 - learning_rate: 0.0100\n",
      "Epoch 2/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1332 - val_loss: 7.7082 - learning_rate: 0.0100\n",
      "Epoch 3/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5187 - val_loss: 6.3935 - learning_rate: 0.0100\n",
      "Epoch 4/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3671 - val_loss: 3.6491 - learning_rate: 0.0100\n",
      "Epoch 5/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1522 - val_loss: 4.4984 - learning_rate: 0.0100\n",
      "Epoch 6/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1291 - val_loss: 3.4514 - learning_rate: 0.0100\n",
      "Epoch 7/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1585 - val_loss: 3.1700 - learning_rate: 0.0100\n",
      "Epoch 8/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0825 - val_loss: 2.6331 - learning_rate: 0.0100\n",
      "Epoch 9/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0385 - val_loss: 2.4861 - learning_rate: 0.0100\n",
      "Epoch 10/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9393 - val_loss: 2.4654 - learning_rate: 0.0100\n",
      "Epoch 11/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9433 - val_loss: 1.8256 - learning_rate: 0.0100\n",
      "Epoch 12/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9222 - val_loss: 1.5208 - learning_rate: 0.0100\n",
      "Epoch 13/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9911 - val_loss: 1.6102 - learning_rate: 0.0100\n",
      "Epoch 14/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0519 - val_loss: 1.5114 - learning_rate: 0.0100\n",
      "Epoch 15/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9478 - val_loss: 1.1413 - learning_rate: 0.0100\n",
      "Epoch 16/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9297 - val_loss: 1.1094 - learning_rate: 0.0100\n",
      "Epoch 17/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8487 - val_loss: 1.1145 - learning_rate: 0.0100\n",
      "Epoch 18/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7528 - val_loss: 1.2668 - learning_rate: 0.0100\n",
      "Epoch 19/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8077 - val_loss: 0.8765 - learning_rate: 0.0100\n",
      "Epoch 20/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8339 - val_loss: 1.1712 - learning_rate: 0.0100\n",
      "Epoch 21/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8718 - val_loss: 0.7496 - learning_rate: 0.0100\n",
      "Epoch 22/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8472 - val_loss: 0.5673 - learning_rate: 0.0100\n",
      "Epoch 23/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8425 - val_loss: 0.9141 - learning_rate: 0.0100\n",
      "Epoch 24/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7762 - val_loss: 0.9055 - learning_rate: 0.0100\n",
      "Epoch 25/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7555 - val_loss: 0.8742 - learning_rate: 0.0100\n",
      "Epoch 26/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8553 - val_loss: 0.9708 - learning_rate: 0.0100\n",
      "Epoch 27/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.8554\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7697 - val_loss: 0.6751 - learning_rate: 0.0100\n",
      "Epoch 28/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6875 - val_loss: 0.5079 - learning_rate: 0.0050\n",
      "Epoch 29/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7069 - val_loss: 0.5877 - learning_rate: 0.0050\n",
      "Epoch 30/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6643 - val_loss: 0.5766 - learning_rate: 0.0050\n",
      "Epoch 31/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6634 - val_loss: 0.4601 - learning_rate: 0.0050\n",
      "Epoch 32/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6602 - val_loss: 0.3959 - learning_rate: 0.0050\n",
      "Epoch 33/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6500 - val_loss: 0.4981 - learning_rate: 0.0050\n",
      "Epoch 34/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6627 - val_loss: 0.5720 - learning_rate: 0.0050\n",
      "Epoch 35/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6606 - val_loss: 0.3651 - learning_rate: 0.0050\n",
      "Epoch 36/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6998 - val_loss: 0.5155 - learning_rate: 0.0050\n",
      "Epoch 37/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7333 - val_loss: 0.3383 - learning_rate: 0.0050\n",
      "Epoch 38/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7188 - val_loss: 0.6698 - learning_rate: 0.0050\n",
      "Epoch 39/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7534 - val_loss: 0.3654 - learning_rate: 0.0050\n",
      "Epoch 40/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6191 - val_loss: 0.5928 - learning_rate: 0.0050\n",
      "Epoch 41/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7092 - val_loss: 0.2910 - learning_rate: 0.0050\n",
      "Epoch 42/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6123 - val_loss: 0.4266 - learning_rate: 0.0050\n",
      "Epoch 43/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6263 - val_loss: 0.3659 - learning_rate: 0.0050\n",
      "Epoch 44/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6653 - val_loss: 0.4638 - learning_rate: 0.0050\n",
      "Epoch 45/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6072 - val_loss: 0.4587 - learning_rate: 0.0050\n",
      "Epoch 46/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6329 - val_loss: 0.2903 - learning_rate: 0.0050\n",
      "Epoch 47/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5990 - val_loss: 0.2902 - learning_rate: 0.0050\n",
      "Epoch 48/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6056 - val_loss: 0.3348 - learning_rate: 0.0050\n",
      "Epoch 49/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6328 - val_loss: 0.3958 - learning_rate: 0.0050\n",
      "Epoch 50/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5929 - val_loss: 0.2795 - learning_rate: 0.0050\n",
      "Epoch 51/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5957 - val_loss: 0.4336 - learning_rate: 0.0050\n",
      "Epoch 52/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6350 - val_loss: 0.5185 - learning_rate: 0.0050\n",
      "Epoch 53/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6273 - val_loss: 0.5129 - learning_rate: 0.0050\n",
      "Epoch 54/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6095 - val_loss: 0.4757 - learning_rate: 0.0050\n",
      "Epoch 55/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6195\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5720 - val_loss: 0.3133 - learning_rate: 0.0050\n",
      "Epoch 56/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5876 - val_loss: 0.3162 - learning_rate: 0.0025\n",
      "Epoch 57/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5578 - val_loss: 0.2789 - learning_rate: 0.0025\n",
      "Epoch 58/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5591 - val_loss: 0.4069 - learning_rate: 0.0025\n",
      "Epoch 59/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5771 - val_loss: 0.2739 - learning_rate: 0.0025\n",
      "Epoch 60/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5594 - val_loss: 0.3635 - learning_rate: 0.0025\n",
      "Epoch 61/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5973 - val_loss: 0.3176 - learning_rate: 0.0025\n",
      "Epoch 62/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5505 - val_loss: 0.2865 - learning_rate: 0.0025\n",
      "Epoch 63/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5284 - val_loss: 0.2670 - learning_rate: 0.0025\n",
      "Epoch 64/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5480 - val_loss: 0.3432 - learning_rate: 0.0025\n",
      "Epoch 65/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5528 - val_loss: 0.3106 - learning_rate: 0.0025\n",
      "Epoch 66/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5925 - val_loss: 0.2694 - learning_rate: 0.0025\n",
      "Epoch 67/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5613 - val_loss: 0.3590 - learning_rate: 0.0025\n",
      "Epoch 68/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5273\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5655 - val_loss: 0.3426 - learning_rate: 0.0025\n",
      "Epoch 69/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5508 - val_loss: 0.2989 - learning_rate: 0.0012\n",
      "Epoch 70/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5448 - val_loss: 0.3093 - learning_rate: 0.0012\n",
      "Epoch 71/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5281 - val_loss: 0.2588 - learning_rate: 0.0012\n",
      "Epoch 72/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5402 - val_loss: 0.2820 - learning_rate: 0.0012\n",
      "Epoch 73/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5433 - val_loss: 0.2559 - learning_rate: 0.0012\n",
      "Epoch 74/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5306 - val_loss: 0.2832 - learning_rate: 0.0012\n",
      "Epoch 75/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5408 - val_loss: 0.2828 - learning_rate: 0.0012\n",
      "Epoch 76/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5654 - val_loss: 0.2668 - learning_rate: 0.0012\n",
      "Epoch 77/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5355 - val_loss: 0.3118 - learning_rate: 0.0012\n",
      "Epoch 78/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5372 - val_loss: 0.2514 - learning_rate: 0.0012\n",
      "Epoch 79/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5174 - val_loss: 0.3270 - learning_rate: 0.0012\n",
      "Epoch 80/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5493 - val_loss: 0.2616 - learning_rate: 0.0012\n",
      "Epoch 81/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4830 - val_loss: 0.3016 - learning_rate: 0.0012\n",
      "Epoch 82/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5483 - val_loss: 0.2714 - learning_rate: 0.0012\n",
      "Epoch 83/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4400\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5528 - val_loss: 0.2809 - learning_rate: 0.0012\n",
      "Epoch 84/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5282 - val_loss: 0.2609 - learning_rate: 6.2500e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4986 - val_loss: 0.2789 - learning_rate: 6.2500e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5144 - val_loss: 0.2823 - learning_rate: 6.2500e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5102 - val_loss: 0.2546 - learning_rate: 6.2500e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6139\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5436 - val_loss: 0.2713 - learning_rate: 6.2500e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5260 - val_loss: 0.2739 - learning_rate: 3.1250e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5048 - val_loss: 0.2682 - learning_rate: 3.1250e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5298 - val_loss: 0.2607 - learning_rate: 3.1250e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5240 - val_loss: 0.2588 - learning_rate: 3.1250e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5186\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5194 - val_loss: 0.2579 - learning_rate: 3.1250e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5048 - val_loss: 0.2491 - learning_rate: 1.5625e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5033 - val_loss: 0.2444 - learning_rate: 1.5625e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5206 - val_loss: 0.2547 - learning_rate: 1.5625e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4928 - val_loss: 0.2653 - learning_rate: 1.5625e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5299 - val_loss: 0.2472 - learning_rate: 1.5625e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5426 - val_loss: 0.2466 - learning_rate: 1.5625e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5419\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5133 - val_loss: 0.2543 - learning_rate: 1.5625e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5276 - val_loss: 0.2621 - learning_rate: 7.8125e-05\n",
      "Epoch 102/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5146 - val_loss: 0.2678 - learning_rate: 7.8125e-05\n",
      "Epoch 103/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5233 - val_loss: 0.2664 - learning_rate: 7.8125e-05\n",
      "Epoch 104/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5091 - val_loss: 0.2619 - learning_rate: 7.8125e-05\n",
      "Epoch 105/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5427\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5191 - val_loss: 0.2622 - learning_rate: 7.8125e-05\n",
      "Epoch 106/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5008 - val_loss: 0.2593 - learning_rate: 3.9062e-05\n",
      "Epoch 107/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4877 - val_loss: 0.2550 - learning_rate: 3.9062e-05\n",
      "Epoch 108/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5093 - val_loss: 0.2541 - learning_rate: 3.9062e-05\n",
      "Epoch 109/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5176 - val_loss: 0.2545 - learning_rate: 3.9062e-05\n",
      "Epoch 110/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5613\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5141 - val_loss: 0.2524 - learning_rate: 3.9062e-05\n",
      "Epoch 111/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5221 - val_loss: 0.2539 - learning_rate: 1.9531e-05\n",
      "Epoch 112/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5149 - val_loss: 0.2553 - learning_rate: 1.9531e-05\n",
      "Epoch 113/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5147 - val_loss: 0.2552 - learning_rate: 1.9531e-05\n",
      "Epoch 114/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4943 - val_loss: 0.2542 - learning_rate: 1.9531e-05\n",
      "Epoch 115/300\n",
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5037\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5141 - val_loss: 0.2544 - learning_rate: 1.9531e-05\n",
      "\n",
      "Modelo robusto guardado\n"
     ]
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "input_dim = X_train_proc.shape[1]\n",
    "\n",
    "def build_robust_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Entrada Grande \n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_1', min_value=128, max_value=512, step=128), \n",
    "        input_shape=(input_dim,)\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01)) # alpha es el equivalente moderno a negative_slope\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Capa Intermedia\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_2', min_value=64, max_value=256, step=64)\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Compresión \n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units_3', min_value=32, max_value=128, step=32)\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(hp.Float('dropout_3', min_value=0.1, max_value=0.3, step=0.1)))\n",
    "    \n",
    "    # Ajuste Fino \n",
    "    model.add(Dense(32))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    #  SALIDA \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 5e-3, 1e-3])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_learning_rate), \n",
    "        loss='mean_absolute_error'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_robust_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_robust_dir',\n",
    "    project_name='house_pricing_robust_tuning'\n",
    ")\n",
    "\n",
    "early_stop_tuner = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "tuner.search(\n",
    "    X_train_proc, y_train_log,\n",
    "    validation_split=0.2, \n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop_tuner],\n",
    "    verbose=0 \n",
    ")\n",
    "\n",
    "# ENTRENAR EL MODELO FINAL\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model_v2 = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop_final = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history_v2 = model_v2.fit(\n",
    "    X_train_proc, y_train_log,\n",
    "    validation_split=0.2,          \n",
    "    epochs=300,          \n",
    "    batch_size=64,       \n",
    "    callbacks=[early_stop_final, reduce_lr],\n",
    "    verbose=1            \n",
    ")\n",
    "\n",
    "model_v2.save('trained_models/modelo_robusto_pinamar.keras')\n",
    "print(\"\\nModelo robusto guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d71140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "\n",
      "Mejor config (Crudo): {'subsample': 0.9, 'n_estimators': 500, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 3, 'learning_rate': 0.05}\n",
      "Modelo crudo guardado'\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "\n",
      "Mejor config (Logaritmo): {'subsample': 0.8, 'n_estimators': 500, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 4, 'learning_rate': 0.05}\n",
      "Modelo logarítmico guardado\n"
     ]
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [500],        \n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],     \n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],                   \n",
    "    'min_samples_leaf': [1, 2, 4],               \n",
    "    'subsample': [0.8, 0.9, 1.0],                \n",
    "    'max_features': ['sqrt', 'log2', None]       \n",
    "}\n",
    "\n",
    "gb_base = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# ENTRENAMIENTO TARGET CRUDO (USD Reales)\n",
    "random_search_raw = RandomizedSearchCV(\n",
    "    estimator=gb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,             \n",
    "    scoring='neg_mean_absolute_percentage_error',\n",
    "    cv=3,                  \n",
    "    verbose=1,\n",
    "    n_jobs=-1,             \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_raw.fit(X_train_proc, y_train)\n",
    "best_gb_raw = random_search_raw.best_estimator_\n",
    "\n",
    "print(\"\\nMejor config (Crudo):\", random_search_raw.best_params_)\n",
    "joblib.dump(best_gb_raw, 'trained_models/modelo_gb_crudo_pinamar.joblib')\n",
    "print(\"Modelo crudo guardado'\")\n",
    "\n",
    "# ENTRENAMIENTO TARGET LOGARÍTMICO\n",
    "random_search_log = RandomizedSearchCV(\n",
    "    estimator=gb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,             \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    cv=3,                  \n",
    "    verbose=1,\n",
    "    n_jobs=-1,             \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_log.fit(X_train_proc, y_train_log)\n",
    "best_gb_log = random_search_log.best_estimator_\n",
    "\n",
    "print(\"\\nMejor config (Logaritmo):\", random_search_log.best_params_)\n",
    "joblib.dump(best_gb_log, 'trained_models/modelo_gb_log_pinamar.joblib')\n",
    "print(\"Modelo logarítmico guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5687742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "Mejor config (Crudo): {'weights': 'distance', 'p': 1, 'n_neighbors': 9, 'metric': 'manhattan'}\n",
      "Modelo crudo guardado\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      " Mejor config (Logaritmo): {'weights': 'distance', 'p': 1, 'n_neighbors': 5, 'metric': 'euclidean'}\n",
      " Modelo logarítmico guardado\n"
     ]
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15, 21], \n",
    "    'weights': ['uniform', 'distance'],  \n",
    "    'metric': ['euclidean', 'manhattan'],  \n",
    "    'p': [1, 2]                            \n",
    "}\n",
    "\n",
    "knn_base = KNeighborsRegressor(n_jobs=-1)\n",
    "\n",
    "# ENTRENAMIENTO TARGET CRUDO (USD Reales)\n",
    "random_search_raw = RandomizedSearchCV(\n",
    "    estimator=knn_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,            \n",
    "    scoring='neg_mean_absolute_percentage_error',\n",
    "    cv=3,                  \n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_raw.fit(X_train_proc, y_train)\n",
    "best_knn_raw = random_search_raw.best_estimator_\n",
    "\n",
    "print(\"\\nMejor config (Crudo):\", random_search_raw.best_params_)\n",
    "joblib.dump(best_knn_raw, 'trained_models/modelo_knn_crudo_pinamar.joblib')\n",
    "print(\"Modelo crudo guardado\")\n",
    "\n",
    "# ENTRENAMIENTO 2: TARGET LOGARÍTMICO\n",
    "random_search_log = RandomizedSearchCV(\n",
    "    estimator=knn_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,             \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    cv=3,                  \n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search_log.fit(X_train_proc, y_train_log)\n",
    "best_knn_log = random_search_log.best_estimator_\n",
    "\n",
    "print(\"\\n Mejor config (Logaritmo):\", random_search_log.best_params_)\n",
    "joblib.dump(best_knn_log, 'trained_models/modelo_knn_log_pinamar.joblib')\n",
    "print(\" Modelo logarítmico guardado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (ML-Manual)",
   "language": "python",
   "name": "kernel_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
